{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Preprocess train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete unneccessary column of training data\n",
    "RAW_DATA = pd.read_csv('data/train.csv', encoding='big5')\n",
    "RAW_DATA.drop(['日期', '測站'], axis=1, inplace=True)\n",
    "RAW_DATA = RAW_DATA.as_matrix()\n",
    "\n",
    "# Calculate and separate the feature number, data, days, end_of_month\n",
    "FEATURE_NUM = len(np.unique(RAW_DATA[:,0]))\n",
    "DATA_SET_LENGTH = 9\n",
    "\n",
    "RAW_DATA = RAW_DATA[:,1:]\n",
    "\n",
    "DAYS = RAW_DATA.shape[0]/FEATURE_NUM\n",
    "END_OF_MONTH = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate array\n",
    "JAN=FEB=MAR=ARI=MAY=JUN=JUL=AUG=SEP=OCT=NOV=DEC=np.array([]).reshape(18,0)\n",
    "MONTHS = [JAN, FEB, MAR, ARI, MAY, JUN, JUL, AUG, SEP, OCT, NOV, DEC] \n",
    "MONTHS_PM = np.array([]).reshape(0,480)\n",
    "    \n",
    "for day in range(int(DAYS)):\n",
    "        MONTHS[int(day/END_OF_MONTH)] = np.concatenate((MONTHS[int(day/END_OF_MONTH)], RAW_DATA[FEATURE_NUM * day : FEATURE_NUM * (day+1),:]), axis=1)\n",
    "\n",
    "# Replace the Rainfall NR string to 0 and create PM2.5 array\n",
    "for month in MONTHS:    \n",
    "    month[month=='NR'] = '0'\n",
    "for month in MONTHS:\n",
    "    MONTHS_PM = np.vstack((MONTHS_PM,month[9,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization of all the params\n",
    "gradient_descent_base = 0\n",
    "gradient_descent_weight_1 = np.zeros([18,9])\n",
    "gradient_descent_bias = 0\n",
    "\n",
    "weight_1 = np.zeros([18,9])\n",
    "bias = 0\n",
    "\n",
    "learning_rate = 1e-10\n",
    "epoch = 100\n",
    "\n",
    "for _ in range(epoch):\n",
    "    gradient_descent_weight_1 = np.zeros([18,9])\n",
    "    gradient_descent_base = gradient_descent_bias = 0\n",
    "    \n",
    "    for number_of_month in range(len(MONTHS)):\n",
    "        for number_of_data in range(MONTHS[number_of_month].shape[1]):\n",
    "            try:\n",
    "                # 2[(y - (b + w*x))]\n",
    "                gradient_descent_base = 2 * (float(MONTHS_PM[number_of_month][number_of_data]) - (bias + (weight_1 * MONTHS[number_of_month][:, number_of_data:DATA_SET_LENGTH+number_of_data].astype(float)).sum()))\n",
    "                gradient_descent_weight_1 += gradient_descent_base * -MONTHS[number_of_month][:, number_of_data:DATA_SET_LENGTH+number_of_data].astype(float)\n",
    "                gradient_descent_bias += gradient_descent_base\n",
    "\n",
    "            except: \n",
    "                pass\n",
    "        \n",
    "    weight_1 -= learning_rate * gradient_descent_weight_1\n",
    "    bias -= learning_rate * gradient_descent_bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proprocess test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete unneccessary column of test data\n",
    "RAW_TEST = pd.read_csv('data/test_X.csv', encoding='big5', header=None)\n",
    "RAW_TEST.drop([1], axis=1, inplace=True)\n",
    "\n",
    "# Replace the Rainfall string data to 0\n",
    "RAW_TEST[RAW_TEST=='NR'] = '0'\n",
    "\n",
    "# Get the test Dataframe of test data and test data ID\n",
    "test_data_ID = RAW_TEST[[0]].as_matrix()\n",
    "test_data = RAW_TEST.iloc[:, RAW_TEST.columns != 0].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the ordered ID of the test data\n",
    "_, idx = np.unique(test_data_ID, return_index=True)\n",
    "order_id = test_data_ID[:,0][np.sort(idx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the result of Predicted PM2.5\n",
    "result = []\n",
    "for number_of_test_data in range(int(test_data.shape[0]/18)):\n",
    "    result.append((weight_1 * test_data[ FEATURE_NUM*number_of_test_data : FEATURE_NUM*(number_of_test_data+1),:].astype(float)).sum() + bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the result and output as submission.csv file\n",
    "========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data=[order_id, result], index=[\"id\", \"value\"]).T.to_csv(\"sampleSubmission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
